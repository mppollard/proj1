{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define path constants\n",
    "LANDING_DATA = '../data/landing/'\n",
    "RAW_DATA = '../data/raw/'\n",
    "CURATED_DATA = '../data/curated/'\n",
    "ANALYSIS_DATA = '../data/analysis/'\n",
    "\n",
    "# max levels for filtering data\n",
    "MAX_FARE = 500\n",
    "MAX_DISTANCE = 100\n",
    "MAX_TIME = 300\n",
    "MAX_LOCATION_ID = 264"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "your 131072x1 screen size is bogus. expect trouble\n",
      "23/08/15 20:49:50 WARN Utils: Your hostname, DESKTOP-VP2PCTV resolves to a loopback address: 127.0.1.1; using 172.21.252.215 instead (on interface eth0)\n",
      "23/08/15 20:49:50 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/08/15 20:49:52 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create a spark session (which will run spark jobs)\n",
    "spark = (\n",
    "    SparkSession.builder.appName(\"MAST30034 Project 1\")\n",
    "    .config(\"spark.sql.repl.eagerEval.enabled\", True) \n",
    "    .config(\"spark.sql.parquet.cacheMetadata\", \"true\")\n",
    "    .config(\"spark.sql.session.timeZone\", \"Etc/UTC\")\n",
    "    .config('spark.driver.memory', '4g')\n",
    "    .config('spark.executor.memory', '2g')\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(source='fhvhv'), Row(source='green'), Row(source='yellow')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.select('source').distinct().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>percentile_approx(fare, 0.9998, 10000)</th></tr>\n",
       "<tr><td>180.0</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+--------------------------------------+\n",
       "|percentile_approx(fare, 0.9998, 10000)|\n",
       "+--------------------------------------+\n",
       "|                                 180.0|\n",
       "+--------------------------------------+"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data3.select(F.percentile_approx(\"fare\", 0.9998))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import DataFrame\n",
    "from typing import Callable\n",
    "from pyspark.sql import functions as F\n",
    "import datetime\n",
    "\n",
    "def apply_filter(data: DataFrame, filter_function: Callable) -> DataFrame:\n",
    "    rows_before_filter = data.count()\n",
    "    data = data.where(filter_function)\n",
    "    print(f'applied filter{str(filter_function)}, rows before:{rows_before_filter}, rows after:{data.count()}')\n",
    "    return data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "import datetime\n",
    "\n",
    "def prepare_curated_tlc_data(source: str, keep_cols: list[str]) -> None:\n",
    "    '''\n",
    "    Retrieves downloaded raw TLC data, combining separate monthly data\n",
    "    into one dataframe, and renames and filters columnsof interest (). \n",
    "    Saves this raw data down accordingly\n",
    "    Arguments:\n",
    "        source = TLC data source (yellow, green, or fhvhv)\n",
    "        rename_cols = dict with keys = original column name, values = new column name\n",
    "    Ouput: None\n",
    "    '''\n",
    "    \n",
    "    # get raw data\n",
    "    all_data = spark.read.parquet(f'{RAW_DATA}{source}/*')\n",
    "    print(f'Number of raw records for {source}: {str(all_data.count())}')\n",
    "    # select columns of interest\n",
    "    all_data = all_data.select(*keep_cols)\n",
    "    \n",
    "    # add derived columns\n",
    "    # adding trip time in minutes\n",
    "    all_data = all_data.withColumn('trip_time', \n",
    "        F.round((all_data.dropoff_datetime- all_data.pickup_datetime).cast('long')/60,2))\n",
    "    # adding temporal variables\n",
    "    all_data = all_data.select('*',\n",
    "        F.hour(\"pickup_datetime\").alias('hour'), \n",
    "        F.month(\"pickup_datetime\").alias('month'), \n",
    "        F.dayofweek(\"pickup_datetime\").alias('day')\n",
    "    )\n",
    "    \n",
    "    # adding an identifier for data source, as curated data will combine all sources\n",
    "    # into one dataframe\n",
    "    all_data=all_data.withColumn('source',F.lit(source))\n",
    "    \n",
    "    # filter out records with suspect data, do this one by one so we can establish\n",
    "    # impact of filters\n",
    "    all_data = apply_filter(all_data, (F.col('fare') > 0) & (F.col('fare') < MAX_FARE))\n",
    "    all_data = apply_filter(all_data, (F.col('trip_distance') > 0) & (F.col('trip_distance') < MAX_DISTANCE))\n",
    "    all_data = apply_filter(all_data, (F.col('trip_time') > 0) & (F.col('trip_time') < MAX_TIME))\n",
    "    all_data = apply_filter(all_data, (F.col('pickup_id') > 0) & (F.col('pickup_id') < MAX_LOCATION_ID))\n",
    "    all_data = apply_filter(all_data, (F.col(\"pickup_datetime\") >= datetime.datetime(2020, 5, 1, 0, 0, 0)) \\\n",
    "        & (F.col(\"pickup_datetime\") < datetime.datetime(2023, 6, 1, 0, 0, 0)))\n",
    "    \n",
    "    # save the curated data\n",
    "    all_data.write.mode('overwrite').parquet(CURATED_DATA+source)\n",
    "    print(f'Number of curated records for {source}: {str(all_data.count())}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of raw records for yellow: 95445749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "applied filterColumn<'((fare > 0) AND (fare < 500))'>, rows before:95445749, rows after:94829572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "applied filterColumn<'((trip_distance > 0) AND (trip_distance < 100))'>, rows before:94829572, rows after:93551616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "applied filterColumn<'((trip_time > 0) AND (trip_time < 300))'>, rows before:93551616, rows after:93340310\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "applied filterColumn<'((pickup_id > 0) AND (pickup_id < 264))'>, rows before:93340310, rows after:92284232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "applied filterColumn<'((pickup_datetime >= TIMESTAMP '2020-04-30 14:00:00') AND (pickup_datetime < TIMESTAMP '2023-05-31 14:00:00'))'>, rows before:92284232, rows after:92215295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of curated records for yellow: 92215295\n",
      "Number of raw records for green: 2877421\n",
      "applied filterColumn<'((fare > 0) AND (fare < 500))'>, rows before:2877421, rows after:2864204\n",
      "applied filterColumn<'((trip_distance > 0) AND (trip_distance < 100))'>, rows before:2864204, rows after:2734280\n",
      "applied filterColumn<'((trip_time > 0) AND (trip_time < 300))'>, rows before:2734280, rows after:2724395\n",
      "applied filterColumn<'((pickup_id > 0) AND (pickup_id < 264))'>, rows before:2724395, rows after:2719252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "applied filterColumn<'((pickup_datetime >= TIMESTAMP '2020-04-30 14:00:00') AND (pickup_datetime < TIMESTAMP '2023-05-31 14:00:00'))'>, rows before:2719252, rows after:2718001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of curated records for green: 2718001\n",
      "Number of raw records for fhvhv: 566168421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "applied filterColumn<'((fare > 0) AND (fare < 500))'>, rows before:566168421, rows after:565300188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "applied filterColumn<'((trip_distance > 0) AND (trip_distance < 100))'>, rows before:565300188, rows after:565131616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "applied filterColumn<'((trip_time > 0) AND (trip_time < 300))'>, rows before:565131616, rows after:565104793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "applied filterColumn<'((pickup_id > 0) AND (pickup_id < 264))'>, rows before:565104793, rows after:565071103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "applied filterColumn<'((pickup_datetime >= TIMESTAMP '2020-04-30 14:00:00') AND (pickup_datetime < TIMESTAMP '2023-05-31 14:00:00'))'>, rows before:565071103, rows after:564757294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 114:====================================================>(140 + 2) / 142]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of curated records for fhvhv: 564757294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "keep_cols = ['pickup_datetime', 'dropoff_datetime', 'trip_distance', 'pickup_id', 'fare']\n",
    "prepare_curated_tlc_data('yellow', keep_cols)\n",
    "prepare_curated_tlc_data('green', keep_cols)\n",
    "prepare_curated_tlc_data('fhvhv', keep_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of raw records for fhvhv: 353752338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "applied filterColumn<'((fare > 0) AND (fare < 500))'>, rows before:353752338, rows after:353166725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "applied filterColumn<'((trip_distance > 0) AND (trip_distance < 100))'>, rows before:353166725, rows after:353056432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "applied filterColumn<'((trip_time > 0) AND (trip_time < 300))'>, rows before:353056432, rows after:353040008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "applied filterColumn<'((pickup_id > 0) AND (pickup_id < 264))'>, rows before:353040008, rows after:353016834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "applied filterColumn<'((pickup_datetime >= TIMESTAMP '2020-04-30 14:00:00') AND (pickup_datetime < TIMESTAMP '2023-05-31 14:00:00'))'>, rows before:353016834, rows after:352703025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 35:=======================================================>(89 + 1) / 90]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of curated records for fhvhv: 352703025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "keep_cols = ['pickup_datetime', 'dropoff_datetime', 'trip_distance', 'pickup_id', 'fare']\n",
    "prepare_curated_tlc_data('fhvhv', keep_cols)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
