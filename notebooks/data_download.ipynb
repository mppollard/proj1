{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Download and File Setup\n",
    "This notebook builds the file structure for the project, and downloads all the landing data into the relevant folder.\n",
    "### Load constants and libraries\n",
    "First of all we load any constant values for use within the notebook, and load any libraries required. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all constants used in the note books\n",
    "from constants import *\n",
    "\n",
    "# libraries required\n",
    "import os, zipfile\n",
    "import itertools\n",
    "from urllib.request import Request,urlopen,urlretrieve\n",
    "from datetime import date, datetime, timedelta\n",
    "import requests\n",
    "from sodapy import Socrata\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build File Structure\n",
    "Only the notebooks and report folder is included in the GitHub repository, the remaining file structure is built here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensure all the required folders are present or created\n",
    "for folder in ALL_FOLDERS:\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)\n",
    "    \n",
    "# create the data sub-folders\n",
    "for target_dir in ALL DATA_SUB: \n",
    "    if not os.path.exists(f'../data/{target_dir}'):\n",
    "        os.makedirs(f'../data/{target_dir}')\n",
    "\n",
    "# create the landing data sub-folders\n",
    "output_relative_dir = '../data/landing/'\n",
    "for target_dir in ALL_SOURCES: \n",
    "    if not os.path.exists(f'../data/landing/{target_dir}'):\n",
    "        os.makedirs(f'../data/landing/{target_dir}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve the Data\n",
    "In this section the following datasets are retrieved: <br>\n",
    "*  taxi data from the TLC website\n",
    "*  NYC shape file data\n",
    "*  NYC weather data via the Iowa State University data repsoitory (https://mesonet.agron.iastate.edu/)\n",
    "*  events data from Data.NY.gov (https://data.ny.gov/Transportation/511-NY-Events-Beginning-2010/ah74-pg4w)<br>\n",
    "\n",
    "I use data from May 2020-May 2023. <br>\n",
    "The weather data set is used to retrieve hourly wind speed, precipitation, and temperature readings from JFK airport. The events dataset is a comprehensive data set of any events that may impact traffic in and around NYC. I filter this dataset at the landing stage, in order to make it more manageable. I filter to only include sports and cultural events, the original dataset includes features such as crashes, construction and road works, and so on. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TLC Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_data(source: str, year: str, month: str) -> None:\n",
    "    '''\n",
    "    Downloads TLC data to the landing stage for a given source (yellow, green, or fhvhv), year and month    \n",
    "    Arguments:\n",
    "        source = TLC data source (yellow, green, or fhvhv)\n",
    "        year = year to download\n",
    "        month = month to download\n",
    "    Ouput: None\n",
    "    '''       \n",
    "    # generate url\n",
    "    get_url = f'{TLC_URL+source+\"_tripdata_\"}{year}-{month}.parquet'\n",
    "    # generate output location and filename\n",
    "    get_path = f'{LANDING_DATA+source+\"/\"}/{year}-{month}.parquet'\n",
    "    # download\n",
    "    urlretrieve(get_url, get_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin year 2020 month 05\n",
      "Completed year 2020 month 05\n",
      "Begin year 2020 month 06\n",
      "Completed year 2020 month 06\n",
      "Begin year 2020 month 07\n",
      "Completed year 2020 month 07\n",
      "Begin year 2020 month 08\n",
      "Completed year 2020 month 08\n",
      "Begin year 2020 month 09\n",
      "Completed year 2020 month 09\n",
      "Begin year 2020 month 10\n",
      "Completed year 2020 month 10\n",
      "Begin year 2020 month 11\n",
      "Completed year 2020 month 11\n",
      "Begin year 2020 month 12\n",
      "Completed year 2020 month 12\n",
      "Begin year 2021 month 01\n",
      "Completed year 2021 month 01\n",
      "Begin year 2021 month 02\n",
      "Completed year 2021 month 02\n",
      "Begin year 2021 month 03\n",
      "Completed year 2021 month 03\n",
      "Begin year 2021 month 04\n",
      "Completed year 2021 month 04\n",
      "Begin year 2021 month 05\n",
      "Completed year 2021 month 05\n",
      "Begin year 2021 month 06\n",
      "Completed year 2021 month 06\n",
      "Begin year 2021 month 07\n",
      "Completed year 2021 month 07\n",
      "Begin year 2021 month 08\n",
      "Completed year 2021 month 08\n",
      "Begin year 2021 month 09\n",
      "Completed year 2021 month 09\n",
      "Begin year 2021 month 10\n",
      "Completed year 2021 month 10\n",
      "Begin year 2021 month 11\n",
      "Completed year 2021 month 11\n",
      "Begin year 2021 month 12\n",
      "Completed year 2021 month 12\n",
      "Begin year 2022 month 01\n",
      "Completed year 2022 month 01\n",
      "Begin year 2022 month 02\n",
      "Completed year 2022 month 02\n",
      "Begin year 2022 month 03\n",
      "Completed year 2022 month 03\n",
      "Begin year 2022 month 04\n",
      "Completed year 2022 month 04\n",
      "Begin year 2022 month 05\n",
      "Completed year 2022 month 05\n",
      "Begin year 2022 month 06\n",
      "Completed year 2022 month 06\n",
      "Begin year 2022 month 07\n",
      "Completed year 2022 month 07\n",
      "Begin year 2022 month 08\n",
      "Completed year 2022 month 08\n",
      "Begin year 2022 month 09\n",
      "Completed year 2022 month 09\n",
      "Begin year 2022 month 10\n",
      "Completed year 2022 month 10\n",
      "Begin year 2022 month 11\n",
      "Completed year 2022 month 11\n",
      "Begin year 2022 month 12\n",
      "Completed year 2022 month 12\n",
      "Begin year 2023 month 01\n",
      "Completed year 2023 month 01\n",
      "Begin year 2023 month 02\n",
      "Completed year 2023 month 02\n",
      "Begin year 2023 month 03\n",
      "Completed year 2023 month 03\n",
      "Begin year 2023 month 04\n",
      "Completed year 2023 month 04\n",
      "Begin year 2023 month 05\n",
      "Completed year 2023 month 05\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# generate the cross product of all years and months in scope\n",
    "months = range(1, 13)\n",
    "all_months = itertools.product(years, months)\n",
    "\n",
    "# iterate through this list and retrieve the data within the start year / month and end year / month constraints\n",
    "for year_month in all_months:\n",
    "    year, month = year_month\n",
    "    if not((year == start_year and month < start_month) | (year == end_year and month > end_month)):        \n",
    "        month = str(month).zfill(2) \n",
    "        print(f\"Begin year {year} month {month}\")\n",
    "        \n",
    "        # retrieve data from all sources in scope\n",
    "        for source in ALL_SOURCES:\n",
    "            retrieve_data(source, year, month)                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shapefile data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieves the taxi zone and shapefile data from the TLC website, unzipping the latter\n",
    "\n",
    "urlretrieve(TAXI_ZONE_CSV, f'{TAXI_ZONE_DATA}taxi+_zone_lookup.csv')\n",
    "local_filename, headers = urlretrieve(url = TAXI_ZONE_SHP)\n",
    "zip_ref = zipfile.ZipFile(file = local_filename, mode = 'r')\n",
    "zip_ref.extractall(path = TAXI_ZONE_DATA)    \n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Weather Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_weather_data(station_id):\n",
    "    '''\n",
    "    Downloads weather data from the Iowa State University repository. Fields are hardcoded to\n",
    "    temperature (in celsius), precipitation, and wind speed\n",
    "    Arguments:\n",
    "        station_id = weather station from which to download data        \n",
    "    Ouput: None\n",
    "    '''   \n",
    "    file_save = f\"{LANDING_DATA}{station_id}.csv\"\n",
    "    \n",
    "    uri = (\n",
    "        \"http://mesonet.agron.iastate.edu/cgi-bin/request/asos.py?\"\n",
    "        f\"station={station_id}&data=tmpc&data=sped&data=p01m&year1=2021&month1=5&day1=1&\"\n",
    "        f\"year2=2023&month2=5&day2=31&\"\n",
    "        \"tz=Etc%2FUTC&format=onlycomma&latlon=no&elev=no&missing=M&trace=T&\"\n",
    "        \"direct=yes&report_type=3\"\n",
    "    )\n",
    "    res = requests.get(uri, timeout=300)\n",
    "    with open(file_save, \"w\", encoding=\"utf-8\") as fh:\n",
    "        fh.write(res.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ Downloading for JFK\n"
     ]
    }
   ],
   "source": [
    "# fetch the weather data for JFK station\n",
    "fetch_weather_data('JFK')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Events Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Requests made without an app_token will be subject to strict throttling limits.\n"
     ]
    }
   ],
   "source": [
    "client = Socrata(\"data.ny.gov\", None)\n",
    "\n",
    "# these are the types of events we want to retrieve, there are many, many more!\n",
    "retrieve_events = \"'baseball game', 'basketball game', 'boxing', 'boxing match', 'carnival', 'concert', 'concert, festival', \\\n",
    "    'concert, fireworks display', 'concert, performing arts', 'concert, race event', 'concert, show', 'concert, special event', \\\n",
    "    'exhibition', 'exhibition, fair', 'fair', 'festival', 'festival, concert', 'festival, gridlock alert day', 'festival, marathon',\\\n",
    "    'festival, parade', 'fireworks', 'fireworks display', 'fireworks display, concert', 'football game', 'football game, fireworks',\\\n",
    "    'hockey game', 'march', 'outdoor market', 'parade', 'parade, festival', 'performing arts', 'play', 'play/show', 'special event',  \\\n",
    "    'special event, concert','sports event', 'street fair', 'tennis tournament', 'trade expo', 'wrestling'\"\n",
    "\n",
    "# retrieve the data, pre-filtered for the desired date range and event types, and also features of interest\n",
    "results = client.get(\"ah74-pg4w\",\n",
    "    select=\"event_type, create_time, close_time, latitude, longitude\",\n",
    "    where=\"create_time>='2020-05-01' AND event_type IN (\" + retrieve_events + \")\",\n",
    "    limit=10000)\n",
    "\n",
    "results_df = pd.DataFrame.from_records(results)\n",
    "results_df.to_csv(f'{LANDING_DATA}events_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
